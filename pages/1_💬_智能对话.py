# ğŸ“œ saga/pages/1_ğŸ’¬_æ™ºèƒ½å¯¹è¯.py

import streamlit as st
import time
import os
import re
import json
from typing import List, Dict
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.exceptions import OutputParserException

# --- å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— ---
from utils.database import db_manager
from utils.knowledge_base import kb_manager
from utils.llm_service import llm_service, count_tokens
from utils.logging_config import logger
from utils.config import config
from utils.prompt_manager import prompt_manager
from utils.pydantic_models import QueryAnalysisResult

# -------------------
# 1. é¡µé¢åŸºç¡€è®¾ç½®
# -------------------
st.set_page_config(page_title="æ™ºèƒ½å¯¹è¯", page_icon="ğŸ’¬", layout="wide")
st.title("ğŸ’¬ æ™ºèƒ½å¯¹è¯")
st.markdown("ä¸æ‚¨çš„AIä¸“å®¶æ™ºå›Šè¿›è¡Œæ·±å…¥äº¤æµ")

# -------------------
# 2. åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
# -------------------
if "current_topic_id" not in st.session_state:
    st.session_state.current_topic_id = None
if "selected_kbs" not in st.session_state:
    st.session_state.selected_kbs = []
if "file_context_for_next_prompt" not in st.session_state:
    st.session_state.file_context_for_next_prompt = None
if "confirming_delete" not in st.session_state:
    st.session_state.confirming_delete = None
if "token_stats" not in st.session_state:
    st.session_state.token_stats = {} # ç”¨äºå­˜å‚¨å’Œæ˜¾ç¤ºTokenæ¶ˆè€—
if "kb_selection_initialized" not in st.session_state:
    st.session_state.kb_selection_initialized = False
    
# ç”¨äºé˜²æ­¢æ–‡ä»¶é‡å¤å¤„ç†çš„æ——æ ‡
if "processed_file_id" not in st.session_state:
    st.session_state.processed_file_id = None
    
# ä½¿ç”¨æ–°çš„å˜é‡æ¥å­˜å‚¨ä¸´æ—¶æ–‡ä»¶ä¸Šä¸‹æ–‡
if "temp_file_text" not in st.session_state:
    st.session_state.temp_file_text = None
    
if "last_response_sources" not in st.session_state:
    st.session_state.last_response_sources = []

# -------------------
# 3. è¾…åŠ©å‡½æ•°
# -------------------
def cut_thinking_txt(text: str) -> str:
    """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤</think>å‰çš„å†…å®¹ï¼Œä¸“é—¨ç”¨äºå¤„ç†æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹ã€‚"""
    if not text: return ""
    pattern = r'(.*?)<\/think>'
    result = re.sub(pattern, '', text, flags=re.DOTALL)
    result = re.sub(r'\n+', '\n', result).strip()
    return result

def auto_generate_title(topic_id, user_prompt, assistant_response):
    """åœ¨é¦–è½®å¯¹è¯åï¼Œè°ƒç”¨LLMä¸ºæ–°è¯é¢˜ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ ‡é¢˜ã€‚"""
    
    title_generation_prompt = prompt_manager.render(
        'title_generation.jinja2', 
        user_prompt=user_prompt, 
        assistant_response=assistant_response
    )

    try:
        messages_for_title = [
            # {"role": "system", "content": "You are an assistant that generates short, concise titles based on a conversation."},
            {"role": "user", "content": title_generation_prompt}
        ]
        # ä½¿ç”¨è½»é‡è°ƒç”¨ï¼Œä¸éœ€è¦ä¸Šä¸‹æ–‡ç®¡ç†
        raw_response = llm_service._lightweight_chat_completion(
            messages_for_title, 
            # topic_id=topic_id, # topic_id ä»éœ€ä¼ é€’ä»¥é¿å…é”™è¯¯
            temperature=0.1
        )
        clean_response = cut_thinking_txt(raw_response)
        if clean_response:
            # æ™ºèƒ½æå–æœ€åä¸€è¡Œæœ‰æ•ˆæ–‡æœ¬ï¼Œå¢å¼ºé²æ£’æ€§
            lines = [line.strip() for line in clean_response.strip().split('\n') if line.strip()]
            new_title = lines[-1] if lines else clean_response
            # è¿›ä¸€æ­¥æ¸…ç†
            new_title = re.sub(r'^[æ ‡é¢˜ï¼š\s"\']+|[\s"\']+$', '', new_title)
            # new_title = new_title[:8] # å¼ºåˆ¶æˆªæ–­
            if new_title:
                db_manager.update_topic_title(topic_id, new_title)
                logger.info(f"ä¸º Topic ID {topic_id} è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜: '{new_title}'")
                return True
    except Exception as e:
        logger.error(f"è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜å¤±è´¥: {e}", exc_info=True)
    return False

def render_citations(response_text: str, source_documents: List[Dict]):
    """è§£æAIå›ç­”ä¸­çš„å¼•ç”¨æ ‡ç­¾ï¼Œå¹¶åœ¨æ–‡æœ«ç»Ÿä¸€å±•ç¤ºå¯å±•å¼€çš„æº¯æºä¿¡æ¯ã€‚"""
    # æ›¿æ¢ä¸»æ–‡æœ¬ä¸­çš„æ ‡ç­¾ï¼Œä½¿å…¶æ›´ç®€æ´
    formatted_response = re.sub(r'\[(æ¥æº-\d+)\]', r' `\1`', response_text)
    st.markdown(formatted_response, unsafe_allow_html=True)

    # æå–æ‰€æœ‰å¼•ç”¨ID
    citation_ids = sorted(list(set(re.findall(r'\[(æ¥æº-\d+)\]', response_text))))
    
    if citation_ids:
        st.markdown("---")
        # æ„å»ºä» citation_id åˆ°æ–‡æ¡£å†…å®¹çš„æ˜ å°„
        citation_map = {doc.get('citation_id'): doc for doc in source_documents if doc.get('citation_id')}
        
        for cid in citation_ids:
            if cid in citation_map:
                source_doc = citation_map[cid]
                with st.expander(f"**{cid}**: {source_doc.get('metadata', {}).get('source', 'æœªçŸ¥æ¥æº')}"):
                    st.markdown(source_doc.get('content', 'å†…å®¹ä¸ºç©º'))

# -------------------
# 4. ä¾§è¾¹æ  (Sidebar)
# -------------------
with st.sidebar:
    st.header("å¯¹è¯ç®¡ç†")
    if st.button("â• æ–°å»ºå¯¹è¯", use_container_width=True):
        new_title = f"æ–°å¯¹è¯ - {time.strftime('%Y-%m-%d %H:%M')}"
        topic_id = db_manager.add_topic(new_title)
        st.session_state.current_topic_id = topic_id
        st.session_state.file_context_for_next_prompt = None
        st.session_state.confirming_delete = None
        st.session_state.token_stats = {} # é‡ç½®tokenç»Ÿè®¡
        st.session_state.kb_selection_initialized = False # é‡ç½®çŸ¥è¯†åº“é€‰æ‹©åˆå§‹åŒ–æ ‡å¿—
        logger.info(f"åˆ›å»ºæ–°ä¸»é¢˜: ID={topic_id}, Title='{new_title}'")
        st.rerun()

    st.divider()

    st.subheader("å†å²å¯¹è¯")
    topics = db_manager.list_topics()
    
    if not st.session_state.current_topic_id and topics:
        st.session_state.current_topic_id = topics[0]['id']

    # --- åˆ é™¤ç¡®è®¤é€»è¾‘ ---
    if st.session_state.confirming_delete:
        topic_to_delete = db_manager.get_topic_by_id(st.session_state.confirming_delete)
        if topic_to_delete:
            with st.expander(f"âš ï¸ ç¡®è®¤åˆ é™¤ '{topic_to_delete['title']}'?", expanded=True):
                st.warning("æ­¤æ“ä½œå°†æ°¸ä¹…åˆ é™¤è¯¥è¯é¢˜åŠå…¶æ‰€æœ‰å¯¹è¯è®°å½•ï¼Œæ— æ³•æ¢å¤ã€‚")
                col1, col2 = st.columns(2)
                if col1.button("ç¡®è®¤", use_container_width=True, type="primary"):
                    # åˆ é™¤ChromaDBä¸­çš„ç›¸å…³é›†åˆï¼ˆå¦‚æœéœ€è¦ï¼‰
                    # kb_manager.delete_collections_for_topic(...) # è¿™æ˜¯ä¸€ä¸ªå¯ä»¥æ‰©å±•çš„åŠŸèƒ½
                    db_manager.delete_topic(st.session_state.confirming_delete)
                    st.session_state.confirming_delete = None
                    st.session_state.current_topic_id = None
                    st.rerun()
                if col2.button("å–æ¶ˆ", use_container_width=True):
                    st.session_state.confirming_delete = None
                    st.rerun()

    # --- æ ‡é¢˜ä¿®æ”¹ä¸å†å²åˆ—è¡¨ ---
    for topic in topics:
        is_selected = (topic['id'] == st.session_state.current_topic_id)

        col1, col2 = st.columns([0.94, 0.06])
        with col1:
            button_type = "primary" if is_selected else "secondary"
            display_title = f"â–¶ {topic['title']}" if is_selected else topic['title']
            if st.button(display_title, use_container_width=True, type=button_type, key=f"topic_btn_{topic['id']}", disabled=is_selected):
                st.session_state.current_topic_id = topic['id']
                # æ¸…é™¤æ‰€æœ‰ä¸´æ—¶ä¸Šä¸‹æ–‡
                st.session_state.file_context_for_next_prompt = None
                st.session_state.temp_file_text = None
                st.session_state.processed_file_id = None
                st.session_state.last_response_sources = []
                st.session_state.confirming_delete = None
                st.session_state.token_stats = {} # åˆ‡æ¢å¯¹è¯æ—¶é‡ç½®
                st.session_state.kb_selection_initialized = False # é‡ç½®çŸ¥è¯†åº“é€‰æ‹©åˆå§‹åŒ–æ ‡å¿—
                st.rerun()
        with col2:
            if st.button("ğŸ—‘ï¸", key=f"del_btn_{topic['id']}", help=f"åˆ é™¤è¯é¢˜ '{topic['title']}'"):
                st.session_state.confirming_delete = topic['id']
                st.rerun()

    st.divider()

    st.subheader("çŸ¥è¯†åº“é€‰æ‹©")

    # è·å–å½“å‰æ¿€æ´»çš„å‘é‡æ¨¡å‹
    active_embedding_model = llm_service.get_active_embedding_model_name()

    # è·å–æ‰€æœ‰çŸ¥è¯†åº“ï¼Œå¹¶è¿‡æ»¤å‡ºä¸å½“å‰æ¨¡å¼å…¼å®¹çš„
    all_kbs = db_manager.list_knowledge_bases()
    compatible_kbs = [kb for kb in all_kbs if kb.get("embedding_model") == active_embedding_model]

    # åˆå§‹åŒ–çŸ¥è¯†åº“é€‰æ‹©ï¼ˆåªåœ¨åˆ‡æ¢å¯¹è¯æˆ–æ–°å»ºå¯¹è¯æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰
    if not st.session_state.kb_selection_initialized and st.session_state.current_topic_id:
        # è·å–è¯¥å¯¹è¯ä¹‹å‰ä½¿ç”¨çš„çŸ¥è¯†åº“
        saved_kb_ids = db_manager.get_topic_knowledge_bases(st.session_state.current_topic_id)

        if saved_kb_ids:
            # æ¢å¤ä¹‹å‰çš„çŸ¥è¯†åº“é€‰æ‹©ï¼ˆåªä¿ç•™ä»ç„¶å­˜åœ¨ä¸”å…¼å®¹çš„ï¼‰
            saved_kb_names = [kb["name"] for kb in compatible_kbs if kb["id"] in saved_kb_ids]
            st.session_state.selected_kbs = saved_kb_names
        else:
            # æ–°å»ºå¯¹è¯ï¼šæ¸…ç©ºçŸ¥è¯†åº“é€‰æ‹©
            st.session_state.selected_kbs = []

        st.session_state.kb_selection_initialized = True
    else:
        # å¦‚æœå·²ç»åˆå§‹åŒ–è¿‡ï¼Œè¿‡æ»¤æ‰ä¸å…¼å®¹çš„çŸ¥è¯†åº“é€‰æ‹©
        if st.session_state.selected_kbs:
            valid_kbs = [kb for kb in all_kbs if kb["name"] in st.session_state.selected_kbs and kb.get("embedding_model") == active_embedding_model]
            st.session_state.selected_kbs = [kb["name"] for kb in valid_kbs]

    # æ˜¾ç¤ºçŸ¥è¯†åº“é€‰æ‹©å™¨ï¼ˆåªæ˜¾ç¤ºå…¼å®¹çš„çŸ¥è¯†åº“ï¼‰
    kb_names = [kb["name"] for kb in compatible_kbs]

    if kb_names:
        new_selected_kbs = st.multiselect(
            "é€‰æ‹©è¦åŠ è½½çš„çŸ¥è¯†åº“ (å¯å¤šé€‰):",
            options=kb_names,
            default=st.session_state.selected_kbs if st.session_state.selected_kbs else [],
            key="kb_selector"
        )

        # æ£€æŸ¥çŸ¥è¯†åº“é€‰æ‹©æ˜¯å¦å‘ç”Ÿå˜åŒ–
        if set(new_selected_kbs) != set(st.session_state.selected_kbs):
            st.session_state.selected_kbs = new_selected_kbs

            # ä¿å­˜åˆ°æ•°æ®åº“
            if st.session_state.current_topic_id:
                new_kb_ids = [kb["id"] for kb in compatible_kbs if kb["name"] in new_selected_kbs]
                db_manager.update_topic_knowledge_bases(st.session_state.current_topic_id, new_kb_ids)

            st.rerun()
    else:
        st.caption("å½“å‰æœåŠ¡æ¨¡å¼ä¸‹æ²¡æœ‰å¯ç”¨çš„çŸ¥è¯†åº“")
    
    st.divider()
    
    # Token æ¶ˆè€—ç»Ÿè®¡
    st.subheader("Token ç»Ÿè®¡")
    stats = st.session_state.get("token_stats", {})
    if stats:
        st.info(f"""
        **ä¸Šæ¬¡äº¤äº’æ¶ˆè€—:**
        - **è¯·æ±‚:** {stats.get('request_tokens', 0)} Tokens
        - **å“åº”:** {stats.get('response_tokens', 0)} Tokens
        - **æ€»è®¡:** {stats.get('total_tokens', 0)} Tokens
        """)
    else:
        st.caption("æš‚æ— Tokenæ¶ˆè€—è®°å½•ã€‚")


# -------------------
# 5. ä¸»èŠå¤©ç•Œé¢
# -------------------
if not st.session_state.current_topic_id:
    st.info("æ¬¢è¿ä½¿ç”¨Sagaï¼Œè¯·ç‚¹å‡»å·¦ä¾§â€œæ–°å»ºå¯¹è¯â€æˆ–é€‰æ‹©ä¸€ä¸ªå†å²å¯¹è¯æ¥å¼€å§‹ã€‚")
else:
    # --- ä¸´æ—¶æ–‡ä»¶ä¸Šä¼ å™¨ ---
    uploaded_file = st.file_uploader(
        "åœ¨æ­¤ä¸Šä¼ ä¸´æ—¶æ–‡ä»¶è¿›è¡Œåˆ†æ (txt, md, pdf, png, jpg):", 
        type=['txt', 'md', 'pdf', 'png', 'jpg', 'jpeg'], 
        key=f"file_uploader_{st.session_state.current_topic_id}"
    )
    if uploaded_file:
        if uploaded_file.file_id != st.session_state.get('processed_file_id'):
            with st.spinner(f"æ­£åœ¨å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ '{uploaded_file.name}'..."):
                file_content = ""
                # ä½¿ç”¨ llm_service çš„ ocr åŠŸèƒ½ç»Ÿä¸€å¤„ç†
                # å…ˆä¿å­˜ä¸´æ—¶æ–‡ä»¶
                temp_dir = os.path.join(config.get('paths.uploads'), "temp")
                os.makedirs(temp_dir, exist_ok=True)
                temp_file_path = os.path.join(temp_dir, uploaded_file.name)
                with open(temp_file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # è°ƒç”¨ llm_service çš„ç»Ÿä¸€æ¥å£
                extraction_result = llm_service.extract_text_from_file(temp_file_path)
                
                if extraction_result and extraction_result.get('text'):
                    file_content = extraction_result.get('text')
                    
                    st.session_state.temp_file_text = file_content
                    st.session_state.processed_file_id = uploaded_file.file_id # è®°å½•å·²å¤„ç†æ–‡ä»¶çš„ID
                    st.success(f"æ–‡ä»¶ '{uploaded_file.name}' å·²å¤„ç†å®Œæ¯•ã€‚è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­å°±æ­¤æ–‡ä»¶æé—®ã€‚")
                else:
                    st.error(f"æ— æ³•ä»æ–‡ä»¶ '{uploaded_file.name}' ä¸­æå–å†…å®¹ã€‚")
                
                if os.path.exists(temp_file_path):
                    os.remove(temp_file_path)

    # --- èŠå¤©è®°å½•æ˜¾ç¤ºï¼šæ¯æ¬¡æ¸²æŸ“éƒ½ä»æ•°æ®åº“é‡æ–°åŠ è½½ï¼Œç¡®ä¿æ•°æ®æœ€æ–° ---
    messages = db_manager.get_messages_by_topic(st.session_state.current_topic_id)
    
    for i, message in enumerate(messages):
        with st.chat_message(message["role"]):
            # åªå¯¹æœ€åä¸€æ¡ assistant æ¶ˆæ¯å°è¯•æ¸²æŸ“æº¯æº
            if message["role"] == "assistant" and i == len(messages) - 1 and st.session_state.last_response_sources:
                render_citations(message["content"], st.session_state.last_response_sources)
            else:
                st.markdown(message["content"], unsafe_allow_html=True)

    # --- ç²˜æ€§èŠå¤©è¾“å…¥æ¡† st.chat_input ä¼šå§‹ç»ˆå›ºå®šåœ¨æµè§ˆå™¨çª—å£åº•éƒ¨---
    if prompt := st.chat_input("è¯·åœ¨æ­¤è¾“å…¥æ‚¨çš„é—®é¢˜... (Shift+Enter æ¢è¡Œ)"):
        
        # ä¿å­˜å¹¶æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        db_manager.add_message(st.session_state.current_topic_id, "user", prompt)
        st.session_state.token_stats = {} # æ¸…ç©ºä¸Šæ¬¡çš„tokenç»Ÿè®¡
        st.rerun()

    # --- AIå“åº”é€»è¾‘ (åœ¨rerunåæ‰§è¡Œï¼Œè¿™æ ·å¯ä»¥ä¿è¯ç•Œé¢å…ˆæ˜¾ç¤ºå‡ºç”¨æˆ·æ¶ˆæ¯) ---
    if messages and messages[-1]["role"] == "user":
        last_user_message_content = messages[-1]["content"]
        
        logger.info(f"æœ€åä¸€æ¡ç”¨æˆ·æé—®å†…å®¹ï¼š{last_user_message_content}")
        
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("ğŸ§  æ€è€ƒä¸­...")
            st.session_state.last_response_sources = [] # é‡ç½®æº¯æºä¿¡æ¯
            
            try:

                # --- ä¸Šä¸‹æ–‡æ„å»º æƒ…æ™¯æ„ŸçŸ¥è·¯ç”± (Context-aware Routing) ---
                context = ""
                
                # æ­¥éª¤1ï¼šæ³¨å…¥ä¸´æ—¶æ–‡ä»¶ä¸Šä¸‹æ–‡
                if st.session_state.get("temp_file_text"):
                    logger.info("æ³¨å…¥ä¸´æ—¶æ–‡ä»¶ä¸Šä¸‹æ–‡ã€‚")
                    context += "--- ä»æ‚¨ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶ä¸­æå–çš„ç›¸å…³ä¿¡æ¯å¦‚ä¸‹ ---\n"
                    context += st.session_state.temp_file_text
                    context += "\n-------------------------------------------\n\n"
                    # ä½¿ç”¨åç«‹å³æ¸…ç©ºï¼Œç¡®ä¿åªå¯¹æœ¬æ¬¡é—®ç­”ç”Ÿæ•ˆ
                    st.session_state.temp_file_text = None
                
                # æ­¥éª¤2ï¼šæ³¨å…¥çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ å’Œ èƒŒæ™¯èµ„æ–™
                # ã€è·¯ç”±åˆ†æ”¯ä¸€ã€‘: éœ€è¦æ‰§è¡ŒçŸ¥è¯†åº“æœç´¢ (Search Path)
                if st.session_state.selected_kbs:
                    with st.spinner("æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“..."):
                        # æ··åˆæŸ¥è¯¢ç­–ç•¥ï¼šä¿ç•™åŸå§‹æŸ¥è¯¢ï¼Œå¹¶åŠ å…¥é‡å†™åçš„æŸ¥è¯¢  + rewritten_queries
                        search_queries = [last_user_message_content]
                        search_queries = list(dict.fromkeys(search_queries)) # å»é‡
                        logger.info(f"æ··åˆæŸ¥è¯¢ç­–ç•¥å·²å¯ç”¨: {search_queries}")
                        
                        kb_ids = [kb['id'] for kb in db_manager.list_knowledge_bases() if kb['name'] in st.session_state.selected_kbs]
                        
                        all_search_results = []
                        seen_contents = set()
                        
                        for query in search_queries:
                            results = kb_manager.search(query, kb_ids=kb_ids)
                            for res in results:
                                if res['content'] not in seen_contents:
                                    all_search_results.append(res)
                                    seen_contents.add(res['content'])
                        
                        if all_search_results:
                            context += "--- ä»æ‚¨çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯å¦‚ä¸‹ ---\n"
                            st.session_state.last_response_sources = all_search_results
                            context_lines = []
                            for res in all_search_results:
                                source_info = f"ã€{res['citation_id']} | æ¥æº: {res['metadata'].get('source', 'æœªçŸ¥')}ã€‘"
                                context_lines.append(f"{source_info}\n{res['content']}")
                            context += "\n".join(context_lines)
                            context += "-------------------------------------------\n"
                            
                    # æ­¥éª¤3ï¼šæ³¨å…¥é€šç”¨èƒŒæ™¯èµ„æ–™
                    background_knowledge = db_manager.get_background_knowledge()
                    if background_knowledge: context += f"\n--- é€šç”¨èƒŒæ™¯èµ„æ–™ ---\n{background_knowledge}\n-------------------\n"
                
                    # --- æ„å»ºæœ€ç»ˆ Prompt ---
                    system_prompt_content = prompt_manager.render('system_prompt.jinja2', context=context)
                    
                else:
                    # ã€è·¯ç”±åˆ†æ”¯äºŒã€‘: ç›´æ¥å›ç­” (Answer-Directly Path)
                    logger.info("è·¯ç”±å†³ç­–: ç›´æ¥å›ç­” (é—²èŠæˆ–æ— çŸ¥è¯†åº“)ã€‚")
                    # ä½¿ç”¨ä¸“ä¸ºé—²èŠè®¾è®¡çš„ã€æå…¶ç®€æ´çš„Promptï¼Œé¿å…Personaè¿‡è½½
                    system_prompt_content = prompt_manager.render('chitchat_prompt.jinja2', context=context)
                
                final_messages_to_send = [{"role": "system", "content": system_prompt_content}]
                final_messages_to_send.extend([{"role": m["role"], "content": m["content"]} for m in messages])
                
                # logger.info(f"åŠ è½½å‰æ–‡æ‰€æœ‰çš„å¯¹è¯ä¿¡æ¯ï¼š{[{"role": m["role"], "content": m["content"]} for m in messages]}")
                
                # --- è°ƒç”¨LLMå¹¶å¤„ç†å“åº” ---
                with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                    full_response, stats = llm_service.chat_completion(
                        final_messages_to_send, 
                        topic_id=st.session_state.current_topic_id
                    )
                    
                st.session_state.token_stats = stats # ä¿å­˜tokenç»Ÿè®¡ä¿¡æ¯

                if full_response:
                    message_placeholder.markdown(full_response, unsafe_allow_html=True)
                    db_manager.add_message(st.session_state.current_topic_id, "assistant", full_response)
                    
                    # 4. æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜
                    current_topic = db_manager.get_topic_by_id(st.session_state.current_topic_id)
                    # åªæœ‰åœ¨æ–°å¯¹è¯çš„ç¬¬ä¸€è½®ä¹‹åæ‰è§¦å‘
                    if current_topic and current_topic['title'].startswith("æ–°å¯¹è¯ -") and len(messages) <= 2:
                        if auto_generate_title(st.session_state.current_topic_id, last_user_message_content, full_response):
                            st.rerun() # ç”Ÿæˆæ ‡é¢˜ååˆ·æ–°ï¼Œæ˜¾ç¤ºæ–°æ ‡é¢˜
                        else:
                            st.rerun()
                    else:
                        st.rerun() # AIå“åº”åï¼Œåˆ·æ–°ä»¥å›ºåŒ–æ¶ˆæ¯
                else:
                    message_placeholder.error("æŠ±æ­‰ï¼Œè·å–AIå›ç­”æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")

            except Exception as e:
                # æ•è·æ¥è‡ª llm_service çš„é”™è¯¯å¹¶åœ¨UIä¸Šæ˜¾ç¤º
                logger.error(f"AIå“åº”ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
                error_message = f"è¯·æ±‚AIæœåŠ¡æ—¶å‘ç”Ÿé”™è¯¯ï¼š\n\n`{str(e)}`\n\nè¯·æ£€æŸ¥ï¼š\n1. `config.yaml`ä¸­çš„APIå¯†é’¥æˆ–æœåŠ¡åœ°å€æ˜¯å¦æ­£ç¡®ã€‚\n2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ã€‚\n3. åå°æ—¥å¿—ä»¥è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
                message_placeholder.error(error_message)

